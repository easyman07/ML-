{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "keras"
      ],
      "metadata": {
        "id": "XNZvVPhNJ8UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "from keras.utils import to_categorical\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
        "# model building\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"The model has a loss of: \", loss)\n",
        "print(\"The model has an accuracy of about: \",accuracy*100,\"%\")"
      ],
      "metadata": {
        "id": "1gK7Don_J7VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear"
      ],
      "metadata": {
        "id": "6hIlab2RJ-DZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5qNjQAwGc7f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "dataset = pd.read_csv(\"Salary_Data.csv\")\n",
        "X = dataset.iloc[:, 0].values\n",
        "y = dataset.iloc[:, 1].values  # Assuming the target variable (salary) is in the second column\n",
        "\n",
        "# Calculate coefficients using the correct formula approach\n",
        "n = len(X)\n",
        "sum_y = np.sum(y)\n",
        "sum_x = np.sum(X)\n",
        "sum_x2 = np.sum(X**2)\n",
        "sum_xy = np.sum(X*y)\n",
        "\n",
        "a = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n",
        "b = (sum_y * sum_x2 - sum_x * sum_xy) / (n * sum_x2 - sum_x**2)\n",
        "\n",
        "# Predict for test data\n",
        "x_test = np.array([1.7, 2.3, 5.4, 7.4, 11.23, 13.56])\n",
        "y_pred = a * x_test + b\n",
        "\n",
        "# Plotting the data points and the regression line\n",
        "plt.scatter(x_test, y_pred, color='red', label='Data points')  # Plot the actual data points\n",
        "# plt.plot(x_test, y_pred, color='blue', label='Regression predictions')  # Plot regression predictions\n",
        "plt.plot(X, a * X + b, color='green', label='Regression line')  # Plot the full regression line\n",
        "plt.title('Linear Regression: Salary Prediction')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "a, b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic"
      ],
      "metadata": {
        "id": "zoKSOtYHKG-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Example data\n",
        "n = 5\n",
        "x1 = np.array([1, 2, 3, 4, 5])\n",
        "x2 = np.array([2, 4, 8, 12, 20])\n",
        "y = np.array([0, 0, 0, 1, 1])\n",
        "# Initial coefficients\n",
        "b0 = 0\n",
        "b1 = 0\n",
        "b2 = 0\n",
        "s = 0.5 # Threshold\n",
        "p = []\n",
        "pc = []\n",
        "# Gradient descent loop\n",
        "for i in range(n):\n",
        "  p_i = 1 / (1 + np.exp(-b0 + b1 * x1[i] + b2 * x2[i]))\n",
        "  p.append(p_i)\n",
        "  b0 = b0 + s * (y[i] - p_i) * p_i * (1 - p_i) * 1\n",
        "  b1 = b1 + s * (y[i] - p_i) * p_i * (1 - p_i) * x1[i]\n",
        "  b2 = b2 + s * (y[i] - p_i) * p_i * (1 - p_i) * x2[i]\n",
        "if p_i > s:\n",
        "  pc.append(1)\n",
        "else:\n",
        "  pc.append(0)\n",
        "print(\"Updated coefficients b0:\", b0,\"b1: \", b1, \"b2: \",b2)\n",
        "# print(\"Predictions:\", pc)\n",
        "print(\"x1: \", x1, \"x2: \",x2, \"actual class: \",y, \"predicted class: \",p)\n",
        "print(\"x1: \", x1)\n",
        "print(\"x2: \", x2)\n",
        "print(\"Actual Class: \", y)\n",
        "print(\"Predicted values: \", p)\n",
        "print(\"Predicted Class: \", pc)"
      ],
      "metadata": {
        "id": "HvGI9JRNKKV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "svm"
      ],
      "metadata": {
        "id": "hkKACSI8KRtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "cancer = load_breast_cancer()\n",
        "cancer\n",
        "cancer.data.shape\n",
        "cancer.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = cancer.data[:, :2]\n",
        "y = cancer.target\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "st_x= StandardScaler()\n",
        "x_train= st_x.fit_transform(x_train)\n",
        "x_test= st_x.transform(x_test)\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='linear', random_state=0)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred= classifier.predict(x_test)\n",
        "y_pred\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test , y_pred)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_test , y_pred)\n",
        "print(\"Precision:\",precision)\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(y_test , y_pred)\n",
        "print(\"Recall:\",recall)\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_test , y_pred)\n",
        "print(\"F1_score:\",f1_score)"
      ],
      "metadata": {
        "id": "Bs3emL3dKTaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hebbian"
      ],
      "metadata": {
        "id": "UIZPGyhGKcyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hebbian_learning(samples):\n",
        "  print(f'{\"INPUT\":^8} {\"TARGET\":^16}{\"WEIGHT CHANGES\":^15}{\"WEIGHTS\":^25}')\n",
        "  w1, w2, b = 0, 0, 0\n",
        "  print(' ' * 45, f'({w1:2}, {w2:2}, {b:2})')\n",
        "  for x1, x2, y in samples:\n",
        "    w1 = w1 + x1 * y\n",
        "    w2 = w2 + x2 * y\n",
        "    b = b + y\n",
        "    print(f'({x1:2}, {x2:2}) {y:2} ({x1*y:2}, {x2*y:2}, {y:2}) ({w1:2}, {w2:2}, {b:2})')\n",
        "AND_samples = {\n",
        "'binary_input_binary_output': [\n",
        "[1, 1, 1],\n",
        "[1, 0, 0],\n",
        "[0, 1, 0],\n",
        "[0, 0, 0]\n",
        "]\n",
        "}\n",
        "OR_samples = {\n",
        "'bipolar_input_bipolar_output': [\n",
        "[ 1, 1, 1],\n",
        "[ 1, -1, 1],\n",
        "[-1, 1, 1],\n",
        "[-1, -1, -1]\n",
        "]\n",
        "}\n",
        "hebbian_learning(AND_samples['binary_input_binary_output'])"
      ],
      "metadata": {
        "id": "uPoJJeWOKcWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mp"
      ],
      "metadata": {
        "id": "NOdM3lC4LLPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNeuron:\n",
        "    def __init__(self, weights, threshold):\n",
        "        self.weights = weights\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Predict the output for a given input using the MP Neuron model.\"\"\"\n",
        "        weighted_sum = sum(w * i for w, i in zip(self.weights, inputs))\n",
        "        return 1 if weighted_sum >= self.threshold else 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"MP Neuron Model for AND Gate with Custom Weights\")\n",
        "\n",
        "    w1 = float(input(\"Enter weight for input 1: \"))\n",
        "    w2 = float(input(\"Enter weight for input 2: \"))\n",
        "    weights = [w1, w2]\n",
        "\n",
        "    threshold = float(input(\"Enter the threshold value: \"))\n",
        "\n",
        "    neuron = MPNeuron(weights, threshold)\n",
        "\n",
        "    inputs_list = [\n",
        "        [0, 0], [0, 1], [1, 0], [1, 1]\n",
        "    ]\n",
        "    t = [0, 0, 0, 1]\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    print(\"Input -> Actual Output : Expected Output\")\n",
        "    for inputs, expected in zip(inputs_list, t):\n",
        "        output = neuron.predict(inputs)\n",
        "        correctness = \"Correct\" if output == expected else \"Wrong\"\n",
        "        print(f\"{inputs} -> {output} : {expected} ({correctness})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ifGQEbByLOY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "single"
      ],
      "metadata": {
        "id": "js9ShcJAMBGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SingleLayerPerceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = 0\n",
        "\n",
        "    def activation_function(self, x):\n",
        "        return np.where(x >= 0, 1, -1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_function(linear_output)\n",
        "                update = self.learning_rate * (y[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation_function(linear_output)\n",
        "\n",
        "\n",
        "# Instantiate the perceptron with a higher number of epochs to ensure learning\n",
        "slp = SingleLayerPerceptron(learning_rate=0.1, epochs=50)\n",
        "\n",
        "# Training data for AND gate\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([-1, -1, -1, 1])  # Outputs for AND gate: false (-1), false (-1), false (-1), true (1)\n",
        "\n",
        "# Training the perceptron\n",
        "slp.fit(X_train, y_train)\n",
        "\n",
        "# Predicting with the trained perceptron to test if it has learned the AND logic\n",
        "predictions = slp.predict(X_train)\n",
        "\n",
        "# Correcting the access to internal variables\n",
        "weights = slp.weights\n",
        "bias = slp.bias\n",
        "\n",
        "# Display the weights, bias, and predictions\n",
        "weights, bias, predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "e-c2Ln01MChs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pca"
      ],
      "metadata": {
        "id": "87XeK-XAOYmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "data = pd.DataFrame(data=np.c_[breast_cancer['data'], breast_cancer['target']],\n",
        "        columns=np.append(breast_cancer['feature_names'], ['target']))\n",
        "\n",
        "data['target'] = data['target'].astype('category')\n",
        "\n",
        "features = breast_cancer['feature_names']\n",
        "data_std = StandardScaler().fit_transform(data[features])\n",
        "\n",
        "# PCA transformation\n",
        "pca = PCA(n_components=27)\n",
        "data_pca = pca.fit_transform(data_std)\n",
        "\n",
        "# Scatter plot of PCA-transformed data\n",
        "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=data['target'].cat.codes, cmap='plasma')\n",
        "plt.title('PCA-Transformed Breast Cancer Data')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_pca, data['target'].cat.codes, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=breast_cancer.target_names, yticklabels=breast_cancer.target_names)\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "R8t_T-Y4OYFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}